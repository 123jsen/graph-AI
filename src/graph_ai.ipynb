{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph AI to Count the Number of Nodes\n",
    "Note that this is not really a graph AI, as it does not learn a graph by reading nodes and surrounding neighbours.\n",
    "Structure of this notebook is a reference to https://github.com/the-deep-learners/deep-learning-illustrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout \n",
    "from keras.layers import BatchNormalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/sample_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(data_path)\n",
    "graph_data = json.load(input_file)\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(graph_data['x_train'])\n",
    "y_train = np.asarray(graph_data['y_train'])\n",
    "x_valid = np.asarray(graph_data['x_valid'])\n",
    "y_valid = np.asarray(graph_data['y_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 64, 64), (10000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(10000, 4096).astype('float32')\n",
    "x_valid = x_valid.reshape(2000, 4096).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4096), (10000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 537,921\n",
      "Trainable params: 537,409\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 1099.8304 - val_loss: 593.3499\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 920.8251 - val_loss: 713.4771\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 751.4169 - val_loss: 722.0159\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 557.9470 - val_loss: 589.6109\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 353.8856 - val_loss: 354.5612\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 193.3050 - val_loss: 221.8456\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 94.4069 - val_loss: 171.4792\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 49.5066 - val_loss: 116.0712\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 35.0736 - val_loss: 117.2355\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 29.5363 - val_loss: 112.2846\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 28.4779 - val_loss: 108.2439\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 28.3386 - val_loss: 100.3280\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 26.7092 - val_loss: 106.4056\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 25.1870 - val_loss: 104.7461\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 24.1186 - val_loss: 103.9133\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 24.5783 - val_loss: 101.6925\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 22.6439 - val_loss: 100.4947\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 21.9887 - val_loss: 104.6042\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 21.8515 - val_loss: 100.1342\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 20.8517 - val_loss: 102.8397\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 21.2091 - val_loss: 100.9503\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 20.7165 - val_loss: 100.3621\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 20.0530 - val_loss: 100.2304\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 21.2226 - val_loss: 99.1389\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 19.3992 - val_loss: 101.3551\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 20.0588 - val_loss: 97.5635\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 20.4342 - val_loss: 99.9948\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 18.8376 - val_loss: 99.0739\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.9107 - val_loss: 99.0611\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 18.4049 - val_loss: 98.7633\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 17.7257 - val_loss: 102.2207\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.6320 - val_loss: 100.8670\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.4590 - val_loss: 98.8915\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.4958 - val_loss: 100.3021\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.3520 - val_loss: 99.2699\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.5779 - val_loss: 100.3295\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.4723 - val_loss: 100.8649\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.3186 - val_loss: 98.9344\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.2481 - val_loss: 99.3637\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.6104 - val_loss: 98.6137\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.3185 - val_loss: 98.0088\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.3108 - val_loss: 99.2568\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.2548 - val_loss: 97.6555\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 17.2213 - val_loss: 100.9094\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.6611 - val_loss: 100.2804\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.2767 - val_loss: 97.3203\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.7714 - val_loss: 100.4551\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.3763 - val_loss: 99.2514\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.5710 - val_loss: 100.9060\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 16.6998 - val_loss: 100.2522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28278eeb010>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128, epochs=50, verbose=1,\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 43,  5, 50, 10, 63, 32, 60, 59, 21])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.719438],\n",
       "       [41.78164 ],\n",
       "       [11.06088 ],\n",
       "       [46.386166],\n",
       "       [17.206064],\n",
       "       [39.375225],\n",
       "       [39.70329 ],\n",
       "       [57.472786],\n",
       "       [45.74622 ],\n",
       "       [17.446133]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.reshape(x_valid[0:10], [10, 4096]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
